{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.17\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /Users/sleebapaul/AML_MSFT/config2.json\n",
      "Workspace Auria is loaded\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Datastore\n",
    "\n",
    "ws = Workspace.from_config(\"../config2.json\")\n",
    "print(\"Workspace {} is loaded\".format(ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'azureml-blobstore-963d160e-9bdd-40a8-852c-1fc06dfe7c7a'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws.get_default_datastore().container_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspaceblobstore AzureBlob azureml-blobstore-963d160e-9bdd-40a8-852c-1fc06dfe7c7a auria5226806917\n",
      "workspacefilestore AzureFile azureml-filestore-963d160e-9bdd-40a8-852c-1fc06dfe7c7a auria5226806917\n",
      "videos AzureBlob videos happypathspublic\n",
      "models AzureBlob styletransfer pipelinedata\n"
     ]
    }
   ],
   "source": [
    "datastores = ws.datastores\n",
    "for name, ds in datastores.items():\n",
    "    print(name, ds.datastore_type, ds.container_name, ds.account_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = os.listdir(\"/Users/sleebapaul/Desktop/coco/text\")\n",
    "print(all_files[0])\n",
    "len(all_files)\n",
    "new_files = []\n",
    "for file in all_files:\n",
    "    file = \"/Users/sleebapaul/Desktop/coco/text/\" + file\n",
    "    new_files.append(file)  \n",
    "print(new_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Datastore.get(ws, datastore_name='workspacefilestore')\n",
    "\n",
    "ds.upload_files(new_files,\n",
    "                  target_path='coco/text',\n",
    "                  overwrite=True,\n",
    "                  show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Datastore.get(ws, datastore_name='workspaceblobstore')\n",
    "\n",
    "ds.upload_files([\"/Users/sleebapaul/Downloads/coco_AttnGAN2.pth\", \"/Users/sleebapaul/Downloads/image_encoder100.pth\",\n",
    "                \"/Users/sleebapaul/Downloads/text_encoder100.pth\"],\n",
    "                  target_path='attnGAN',\n",
    "                  overwrite=True,\n",
    "                  show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enabling widget\n",
    "The widget will help visualize the pipeline and monitor the progress of the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing /usr/local/lib/python3.7/site-packages/azureml/widgets/static -> azureml_widgets\n",
      "Up to date: /Users/sleebapaul/Library/Jupyter/nbextensions/azureml_widgets/index.js\n",
      "Up to date: /Users/sleebapaul/Library/Jupyter/nbextensions/azureml_widgets/extension.js\n",
      "Up to date: /Users/sleebapaul/Library/Jupyter/nbextensions/azureml_widgets/packages/labextension/azureml_widgets-1.0.0.tgz\n",
      "- Validating: \u001b[32mOK\u001b[0m\n",
      "\n",
      "    To initialize this nbextension in the browser every time the notebook (or other app) loads:\n",
      "    \n",
      "          jupyter nbextension enable azureml.widgets --user --py\n",
      "    \n",
      "Enabling notebook extension azureml_widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension install --py --user azureml.widgets\n",
    "!jupyter nbextension enable --py --user azureml.widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to the datastore\n",
    "We are uploading the training data and current production model to the datastore that is attached to the workspace. We will use these files later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpucluster\n",
      "gpuclusterNCv2\n",
      "gpuclusterNCv3\n"
     ]
    }
   ],
   "source": [
    "cts = ws.compute_targets\n",
    "for ct in cts:\n",
    "    print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target: cpucluster\n",
      "Found existing compute target: gpuclusterNCv2\n",
      "Found existing compute target: gpuclusterNCv3\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "\n",
    "# CPU Cluster\n",
    "cpu_compute_target = \"cpucluster\"\n",
    "\n",
    "try:\n",
    "    cpu_compute = AmlCompute(ws, cpu_compute_target)\n",
    "    print(\"Found existing compute target: {}\".format(cpu_compute.name))\n",
    "except:\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\n",
    "                                                                min_nodes = 1,\n",
    "                                                                max_nodes = 4)\n",
    "    cpu_compute = AmlCompute.create(ws, cpu_compute_target, provisioning_config)\n",
    "    cpu_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    print(\"Created new compute target: {}\".format(cpu_compute.name))\n",
    "\n",
    "# GPU Cluster\n",
    "gpu_compute_target = \"gpuclusterNCv2\"\n",
    "\n",
    "try:\n",
    "    gpu_compute = AmlCompute(ws, gpu_compute_target)\n",
    "    print(\"Found existing compute target: {}\".format(gpu_compute.name))\n",
    "except:\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_NC6S_V2\",\n",
    "                                                                min_nodes = 1,\n",
    "                                                                max_nodes = 4)\n",
    "    gpu_compute = AmlCompute.create(ws, gpu_compute_target, provisioning_config)\n",
    "    gpu_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    print(\"Created new compute target: {}\".format(gpu_compute.name))\n",
    "    \n",
    "    \n",
    "gpu_compute_target = \"gpuclusterNCv3\"\n",
    "\n",
    "try:\n",
    "    gpu_compute = AmlCompute(ws, gpu_compute_target)\n",
    "    print(\"Found existing compute target: {}\".format(gpu_compute.name))\n",
    "except:\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_NC6S_V3\",\n",
    "                                                                min_nodes = 1,\n",
    "                                                                max_nodes = 4)\n",
    "    gpu_compute = AmlCompute.create(ws, gpu_compute_target, provisioning_config)\n",
    "    gpu_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    print(\"Created new compute target: {}\".format(gpu_compute.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpuclusterNCv3'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_compute.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Pipeline\n",
    "A Step is a unit of execution. Step typically needs a target of execution (compute target), a script to execute, and may require script arguments and inputs, and can produce outputs. The step also could take a number of other parameters. Azure Machine Learning Pipelines currently has these built-in Steps: [PythonScriptStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.python_script_step.pythonscriptstep?view=azure-ml-py), [EstimatorStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.estimator_step.estimatorstep?view=azure-ml-py), [MpiStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.mpi_step.mpistep?view=azure-ml-py), [AdlaStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.adla_step.adlastep?view=azure-ml-py), [DataTransferStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.data_transfer_step.datatransferstep?view=azure-ml-py), [DatabricksStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.databricks_step.databricksstep?view=azure-ml-py), and [HyperDriveStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.hyper_drive_step.hyperdrivestep?view=azure-ml-py).\n",
    "\n",
    "### Define a Pipeline Step with inputs and outputs \n",
    "#### Modeling input data\n",
    "A step in the pipeline can take data as input. This data can be a data source that lives in one of the accessible data locations, or intermediate data produced by a previous step in the pipeline. An already existing data is typically called a Datasource and is represented by [DataReference](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.data_reference.datareference?view=azure-ml-py) object. A DataReference could be a pointer to a file or a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataReference object created\n"
     ]
    }
   ],
   "source": [
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.core import PipelineData\n",
    "\n",
    "bs = Datastore.get(ws, datastore_name='workspaceblobstore')\n",
    "coco_AttnGAN2 = DataReference(\n",
    "    datastore=bs,\n",
    "    data_reference_name=\"coco_AttnGAN2\",\n",
    "    path_on_datastore=\"coco_AttnGAN2.pth\")\n",
    "\n",
    "image_encoder100 = DataReference(\n",
    "    datastore=bs,\n",
    "    data_reference_name=\"image_encoder100\",\n",
    "    path_on_datastore=\"image_encoder100.pth\")\n",
    "\n",
    "text_encoder100 = DataReference(\n",
    "    datastore=bs,\n",
    "    data_reference_name=\"text_encoder100\",\n",
    "    path_on_datastore=\"text_encoder100.pth\")\n",
    "\n",
    "fs = Datastore.get(ws, datastore_name='workspacefilestore')\n",
    "data_dir = DataReference(\n",
    "    datastore=fs,\n",
    "    data_reference_name=\"coco\",\n",
    "    path_on_datastore=\"coco\")\n",
    "\n",
    "output_dir = PipelineData(name=\"generated_images\", \n",
    "                          datastore=fs, \n",
    "                          output_path_on_compute=\"generated_images\")\n",
    "                          \n",
    "input_text = PipelineParameter(name=\"input_text\", default_value=\"sky beach evening\")\n",
    "\n",
    "print(\"DataReference object created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version:  3.6.2\n",
      "trainStep step created\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.steps import MpiStep\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "\n",
    "\n",
    "project_folder = \"../attnGAN/\"\n",
    "\n",
    "from azureml.core.runconfig import CondaDependencies, RunConfiguration\n",
    "\n",
    "nodecount_param = PipelineParameter(name=\"nodecount\", default_value=3)\n",
    "\n",
    "cd = CondaDependencies()\n",
    "print(\"Python Version: \", cd.get_python_version())\n",
    "\n",
    "cd.add_channel(\"conda-forge\")\n",
    "cd.add_channel(\"pytorch\")\n",
    "cd.add_conda_package(\"pytorch\")\n",
    "cd.add_conda_package(\"torchvision\")\n",
    "\n",
    "# Runconfig\n",
    "amlcompute_run_config = RunConfiguration(conda_dependencies=cd)\n",
    "amlcompute_run_config.environment.docker.enabled = True\n",
    "amlcompute_run_config.environment.docker.gpu_support = True\n",
    "amlcompute_run_config.environment.docker.base_image = \"pytorch/pytorch\"\n",
    "amlcompute_run_config.environment.spark.precache_packages = False\n",
    "\n",
    "trainStep = MpiStep(\n",
    "    name=\"text_to_image_step\",\n",
    "    script_name=\"gen_art.py\",\n",
    "    arguments=[\"--gpu\", 0,  \n",
    "               \"--data_dir\", data_dir, \n",
    "               \"--model_path\", coco_AttnGAN2,\n",
    "               \"--textencoder_path\", text_encoder100,\n",
    "               \"--output_dir\", output_dir,\n",
    "               \"--input_text\", input_text\n",
    "              ],\n",
    "    inputs=[data_dir, coco_AttnGAN2, text_encoder100],\n",
    "    outputs=[output_dir],\n",
    "    compute_target=gpu_compute,\n",
    "    node_count=nodecount_param, \n",
    "    process_count_per_node=1,\n",
    "    pip_packages=[\"mpi4py\", \"torch\", \"torchvision\", \"numpy\", \"nltk\",\"easydict\",\"pandas\", \"Pillow\" ,\"scikit-image\"],\n",
    "    source_directory=project_folder,\n",
    "    runconfig=amlcompute_run_config,\n",
    "    use_gpu=True,\n",
    "    allow_reuse=True)\n",
    "\n",
    "print(\"trainStep step created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built\n",
      "Step text_to_image_step is ready to be created [5a891898]\n",
      "Pipeline validation complete\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "# steps = [dataprepStep, trainStep, compareStep]\n",
    "\n",
    "steps = [ trainStep ]\n",
    "\n",
    "training_pipeline = Pipeline(workspace=ws, steps=steps)\n",
    "print(\"Pipeline is built\")\n",
    "\n",
    "training_pipeline.validate()\n",
    "print(\"Pipeline validation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the pipeline\n",
    "[Submitting](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipeline.pipeline?view=azure-ml-py#submit) the pipeline involves creating an [Experiment](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment?view=azure-ml-py) object and providing the built pipeline for submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step text_to_image_step [5a891898][a55aee04-c0c9-4d52-b0fd-431aced44b39], (This step will run and generate new outputs)\n",
      "Using data reference coco for StepId [e94a902c][3b008c6a-fd9f-4adb-9065-5d40e43a2cfd], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Using data reference coco_AttnGAN2 for StepId [09a1acd8][16966b0d-2190-4995-b0e1-4d113d20ff63], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Using data reference text_encoder100 for StepId [bb06aee2][20934fa7-7db5-477f-9e8a-59eb1a0376af], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Submitted pipeline run: d0e3df3c-a995-4e47-8b28-3afbbc63cd81\n",
      "Pipeline is submitted for execution\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "training_pipeline_run = Experiment(ws, 'Text_to_Image_Experiment').submit(\n",
    "    training_pipeline, \n",
    "    pipeline_params={\"input_text\": \"I love my mother\"},\n",
    "    regenerate_outputs=False)\n",
    "print(\"Pipeline is submitted for execution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish the pipeline\n",
    "Once you are satisfied with the results of your experiment, you may want to publish the pipeline to get a REST endpoint so the pipeline can be invoked later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_training_pipeline = training_pipeline.publish(name=\"Compare_Models_Pipeline\",\n",
    "                                                        description=\"This pipeline compares models\")\n",
    "print(\"The published pipeline ID is {}\".format(published_training_pipeline.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run published pipeline using its REST endpoint\n",
    "To invoke the run of the preceding pipeline, you need an Azure Active Directory authentication header token, as described in [AzureCliAuthentication](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.authentication.azurecliauthentication?view=azure-ml-py) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "import requests\n",
    "\n",
    "cli_auth = InteractiveLoginAuthentication()\n",
    "aad_token = cli_auth.get_authentication_header()\n",
    "\n",
    "training_pipeline_rest_ep = published_training_pipeline.endpoint\n",
    "\n",
    "print(\"The published pipeline REST endpoint is {}\".format(training_pipeline_rest_ep))\n",
    "\n",
    "# specify the param when running the pipeline\n",
    "response = requests.post(training_pipeline_rest_ep,\n",
    "                         headers=aad_token,\n",
    "                         json={\"ExperimentName\": \"Compare_v2_Models_Experiment\",\n",
    "                               \"RunSource\": \"SDK\",\n",
    "                               \"ParameterAssignments\": {\"model_version\": 2.0}})\n",
    "pipeline_run_id = response.json()[\"Id\"]\n",
    "\n",
    "print(\"The run ID is {}\".format(pipeline_run_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the run\n",
    "We can examine the run of the pipeline that we just invoked via the REST endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineRun\n",
    "pub_pipeline_run = PipelineRun(Experiment(ws, \"Compare_v2_Models_Experiment\"), pipeline_run_id)\n",
    "RunDetails(pub_pipeline_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you!\n",
    "Thank you! "
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "diray"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
